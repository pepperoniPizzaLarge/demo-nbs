{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook was created and run on Kaggle and has not been tested in other environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:06.017829Z",
     "iopub.status.busy": "2024-06-06T09:50:06.017485Z",
     "iopub.status.idle": "2024-06-06T09:50:06.024752Z",
     "shell.execute_reply": "2024-06-06T09:50:06.023699Z",
     "shell.execute_reply.started": "2024-06-06T09:50:06.017798Z"
    }
   },
   "outputs": [],
   "source": [
    "# upgrade transformers to use save_strategy='epoch'\n",
    "# !pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:06.026533Z",
     "iopub.status.busy": "2024-06-06T09:50:06.026047Z",
     "iopub.status.idle": "2024-06-06T09:50:06.036611Z",
     "shell.execute_reply": "2024-06-06T09:50:06.035781Z",
     "shell.execute_reply.started": "2024-06-06T09:50:06.026497Z"
    }
   },
   "outputs": [],
   "source": [
    "# installing evaluate to calculate accuracy \n",
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:06.038479Z",
     "iopub.status.busy": "2024-06-06T09:50:06.038133Z",
     "iopub.status.idle": "2024-06-06T09:50:31.161768Z",
     "shell.execute_reply": "2024-06-06T09:50:31.160962Z",
     "shell.execute_reply.started": "2024-06-06T09:50:06.038452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:50:17.005284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-06 09:50:17.005415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-06 09:50:17.280630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af9a243e284f3e9a570018609c1941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import set_seed\n",
    "\n",
    "set_seed(1122) # for reproducible code\n",
    "dataset = load_dataset('json', data_files='/kaggle/input/nlpa2-dataset/A2 dataset/train.jsonl') # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.164023Z",
     "iopub.status.busy": "2024-06-06T09:50:31.163018Z",
     "iopub.status.idle": "2024-06-06T09:50:31.179795Z",
     "shell.execute_reply": "2024-06-06T09:50:31.178929Z",
     "shell.execute_reply.started": "2024-06-06T09:50:31.163985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': 'train-1',\n",
       " 'Question': 'There is a light rain today. What happened as a result?',\n",
       " 'Alternative1': 'The roots of many plants are not moistened by rain.',\n",
       " 'Alternative2': 'Tourists have seen many ripples.',\n",
       " 'Answer': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.182825Z",
     "iopub.status.busy": "2024-06-06T09:50:31.182344Z",
     "iopub.status.idle": "2024-06-06T09:50:31.228808Z",
     "shell.execute_reply": "2024-06-06T09:50:31.227845Z",
     "shell.execute_reply.started": "2024-06-06T09:50:31.182766Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# train_test_split and build HF DatasetDict\n",
    "train_test_valid = dataset['train'].train_test_split(test_size=0.1)\n",
    "# test_valid = train_test_valid['test'].train_test_split(test_size=0.5)\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_valid['train'],\n",
    "    'valid': train_test_valid['test'],\n",
    "#     'valid': test_valid['train']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.230413Z",
     "iopub.status.busy": "2024-06-06T09:50:31.230038Z",
     "iopub.status.idle": "2024-06-06T09:50:31.236492Z",
     "shell.execute_reply": "2024-06-06T09:50:31.235643Z",
     "shell.execute_reply.started": "2024-06-06T09:50:31.230379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'Answer'],\n",
       "        num_rows: 13420\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'Answer'],\n",
       "        num_rows: 1492\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.237922Z",
     "iopub.status.busy": "2024-06-06T09:50:31.237650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043d779127d54317bb2f7bd562f523e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load eval.json set\n",
    "testset = load_dataset('json', data_files='/kaggle/input/nlpa2-dataset/A2 dataset/eval.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.444013Z",
     "iopub.status.busy": "2024-06-06T09:50:31.443719Z",
     "iopub.status.idle": "2024-06-06T09:50:31.474715Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding a throw-away lable column so that the preprocess function can be reused on the eval.jsonl set with minimal revision\n",
    "_col = [1]*len(testset['train'])\n",
    "testset_new = testset['train'].add_column(\"label\", _col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:31.476516Z",
     "iopub.status.busy": "2024-06-06T09:50:31.476098Z",
     "iopub.status.idle": "2024-06-06T09:50:33.954274Z",
     "shell.execute_reply": "2024-06-06T09:50:33.953442Z",
     "shell.execute_reply.started": "2024-06-06T09:50:31.476479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d27d8e2883d4e45a72f4226c9c82f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:33.955747Z",
     "iopub.status.busy": "2024-06-06T09:50:33.955461Z",
     "iopub.status.idle": "2024-06-06T09:50:36.176495Z",
     "shell.execute_reply": "2024-06-06T09:50:36.175683Z",
     "shell.execute_reply.started": "2024-06-06T09:50:33.955714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b8f4c035944718a4351bdef7dde792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37fea9ff28e4cd08aa61d2399f4b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3d91603e3848658899b74987182384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DebertaV2TokenizerFast\n",
    "# load tokenizer\n",
    "tokenizer_deberta = DebertaV2TokenizerFast.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:36.181675Z",
     "iopub.status.busy": "2024-06-06T09:50:36.180846Z",
     "iopub.status.idle": "2024-06-06T09:50:36.189189Z",
     "shell.execute_reply": "2024-06-06T09:50:36.188380Z",
     "shell.execute_reply.started": "2024-06-06T09:50:36.181635Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preproces & tokenize function for training dataset\n",
    "\"\"\"\n",
    "ans_names = ['Alternative1', 'Alternative2']\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    questions = [[context] * 2 for context in examples[\"Question\"]]\n",
    "    answers = [[f\"{examples[ans][i]}\" for ans in ans_names] for i in range(len(examples['Answer']))]\n",
    "    \n",
    "    questions = sum(questions, [])\n",
    "    answers = sum(answers, [])\n",
    "    \n",
    "    tokenized_examples = tokenizer_deberta(questions, answers, truncation=True, max_length=256) #max_length=\n",
    "    \n",
    "    return {k: [v[i : i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:36.190792Z",
     "iopub.status.busy": "2024-06-06T09:50:36.190523Z",
     "iopub.status.idle": "2024-06-06T09:50:39.533148Z",
     "shell.execute_reply": "2024-06-06T09:50:39.532207Z",
     "shell.execute_reply.started": "2024-06-06T09:50:36.190770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6e19b74b6b40ad8cf9ac97810f9e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2946b76492c24216a48db91ed1ae1a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1492 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:39.534925Z",
     "iopub.status.busy": "2024-06-06T09:50:39.534510Z",
     "iopub.status.idle": "2024-06-06T09:50:39.543456Z",
     "shell.execute_reply": "2024-06-06T09:50:39.542399Z",
     "shell.execute_reply.started": "2024-06-06T09:50:39.534892Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess & tokenize function for test dataset (eval.jsonl)\n",
    "\"\"\"\n",
    "\n",
    "ans_names = ['Alternative1', 'Alternative2']\n",
    "\n",
    "def preprocess_function_testset(examples):\n",
    "    questions = [[context] * 2 for context in examples[\"Question\"]]\n",
    "    answers = [[f\"{examples[ans][i]}\" for ans in ans_names] for i in range(len(examples['label']))]\n",
    "    \n",
    "    questions = sum(questions, [])\n",
    "    answers = sum(answers, [])\n",
    "    \n",
    "    tokenized_examples = tokenizer_deberta(questions, answers, truncation=True)\n",
    "    \n",
    "    return {k: [v[i : i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:39.544822Z",
     "iopub.status.busy": "2024-06-06T09:50:39.544568Z",
     "iopub.status.idle": "2024-06-06T09:50:40.250662Z",
     "shell.execute_reply": "2024-06-06T09:50:40.249791Z",
     "shell.execute_reply.started": "2024-06-06T09:50:39.544799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706a2aa9157c4df6a987e3123911a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 4261\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "encoded_testset_new = testset_new.map(preprocess_function_testset, batched=True)\n",
    "print(encoded_testset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.252394Z",
     "iopub.status.busy": "2024-06-06T09:50:40.251990Z",
     "iopub.status.idle": "2024-06-06T09:50:40.257751Z",
     "shell.execute_reply": "2024-06-06T09:50:40.256788Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.252357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'Answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 13420\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'Answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1492\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 4261\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dataset)\n",
    "print(encoded_testset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.275831Z",
     "iopub.status.busy": "2024-06-06T09:50:40.275559Z",
     "iopub.status.idle": "2024-06-06T09:50:40.287008Z",
     "shell.execute_reply": "2024-06-06T09:50:40.286301Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.275807Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs to the longest sequence length of the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name)-1 for feature in features] # changed this\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.288349Z",
     "iopub.status.busy": "2024-06-06T09:50:40.288015Z",
     "iopub.status.idle": "2024-06-06T09:50:40.308238Z",
     "shell.execute_reply": "2024-06-06T09:50:40.307399Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.288325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 13420\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['Id', 'Question', 'Alternative1', 'Alternative2', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1492\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# rename \"Answer\" column to \"label\" for straight-forward training\n",
    "encoded_dataset = encoded_dataset.rename_column(\"Answer\", \"label\")\n",
    "print(encoded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.310245Z",
     "iopub.status.busy": "2024-06-06T09:50:40.309435Z",
     "iopub.status.idle": "2024-06-06T09:50:40.350829Z",
     "shell.execute_reply": "2024-06-06T09:50:40.350021Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.310212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# testing the data collator\n",
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items() if k in accepted_keys} for i in range(3)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer_deberta)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.352190Z",
     "iopub.status.busy": "2024-06-06T09:50:40.351906Z",
     "iopub.status.idle": "2024-06-06T09:50:40.379531Z",
     "shell.execute_reply": "2024-06-06T09:50:40.378724Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.352152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.386819Z",
     "iopub.status.busy": "2024-06-06T09:50:40.386516Z",
     "iopub.status.idle": "2024-06-06T09:50:40.399665Z",
     "shell.execute_reply": "2024-06-06T09:50:40.398679Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.386794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] This country has advanced seawater desalination technology. What happened as a result?[SEP] It has introduced deluxe shoelaces.[SEP][PAD][PAD][PAD][PAD][PAD]',\n",
       " '[CLS] This country has advanced seawater desalination technology. What happened as a result?[SEP] The arid country turns the bay into its water source.[SEP]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer_deberta.decode(batch[\"input_ids\"][1][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:50:40.401012Z",
     "iopub.status.busy": "2024-06-06T09:50:40.400726Z",
     "iopub.status.idle": "2024-06-06T09:50:50.899080Z",
     "shell.execute_reply": "2024-06-06T09:50:50.898310Z",
     "shell.execute_reply.started": "2024-06-06T09:50:40.400956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cc22b471ac42b0b1e94097cce1b4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/993 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9a71597ab0467a9fb69e7b55e6e0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model_deberta = AutoModelForMultipleChoice.from_pretrained(\"OpenAssistant/reward-model-deberta-v3-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:53:14.114832Z",
     "iopub.status.busy": "2024-06-06T09:53:14.113837Z",
     "iopub.status.idle": "2024-06-06T11:21:05.931977Z",
     "shell.execute_reply": "2024-06-06T11:21:05.930523Z",
     "shell.execute_reply.started": "2024-06-06T09:53:14.114787Z"
    }
   },
   "outputs": [],
   "source": [
    "# training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"NLP_A2_3rd\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=6e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=50,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_deberta,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer_deberta,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer_deberta),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:21:39.750356Z",
     "iopub.status.busy": "2024-06-06T11:21:39.749011Z",
     "iopub.status.idle": "2024-06-06T11:24:05.191309Z",
     "shell.execute_reply": "2024-06-06T11:24:05.190058Z",
     "shell.execute_reply.started": "2024-06-06T11:21:39.750324Z"
    }
   },
   "outputs": [],
   "source": [
    "# create predictions\n",
    "preds_output = trainer.predict(encoded_testset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:24:24.021515Z",
     "iopub.status.busy": "2024-06-06T11:24:24.020788Z",
     "iopub.status.idle": "2024-06-06T11:24:24.027233Z",
     "shell.execute_reply": "2024-06-06T11:24:24.025785Z",
     "shell.execute_reply.started": "2024-06-06T11:24:24.021481Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = preds_output.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:24:26.709168Z",
     "iopub.status.busy": "2024-06-06T11:24:26.708778Z",
     "iopub.status.idle": "2024-06-06T11:24:26.725344Z",
     "shell.execute_reply": "2024-06-06T11:24:26.724054Z",
     "shell.execute_reply.started": "2024-06-06T11:24:26.709110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.4604678 ,  0.77434206],\n",
       "       [ 9.338473  ,  2.7560866 ],\n",
       "       [-1.4056066 , 11.298847  ],\n",
       "       ...,\n",
       "       [ 1.9643338 ,  8.827789  ],\n",
       "       [11.742342  , -3.0449402 ],\n",
       "       [-9.259441  , -1.6466047 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions  # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:24:28.814326Z",
     "iopub.status.busy": "2024-06-06T11:24:28.813931Z",
     "iopub.status.idle": "2024-06-06T11:24:28.821822Z",
     "shell.execute_reply": "2024-06-06T11:24:28.820838Z",
     "shell.execute_reply.started": "2024-06-06T11:24:28.814295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4261\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(predictions, axis=1)\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:24:30.601151Z",
     "iopub.status.busy": "2024-06-06T11:24:30.600762Z",
     "iopub.status.idle": "2024-06-06T11:24:30.666525Z",
     "shell.execute_reply": "2024-06-06T11:24:30.665453Z",
     "shell.execute_reply.started": "2024-06-06T11:24:30.601108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target\n",
       "0       1\n",
       "1       1\n",
       "2       2\n",
       "3       2\n",
       "4       1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(preds)\n",
    "df.columns = ['Target']\n",
    "\n",
    "df['Target'] = df['Target']+1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:24:32.624906Z",
     "iopub.status.busy": "2024-06-06T11:24:32.623976Z",
     "iopub.status.idle": "2024-06-06T11:24:32.642303Z",
     "shell.execute_reply": "2024-06-06T11:24:32.641305Z",
     "shell.execute_reply.started": "2024-06-06T11:24:32.624871Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T11:27:31.325255Z",
     "iopub.status.busy": "2024-06-06T11:27:31.324844Z",
     "iopub.status.idle": "2024-06-06T11:27:31.355205Z",
     "shell.execute_reply": "2024-06-06T11:27:31.353847Z",
     "shell.execute_reply.started": "2024-06-06T11:27:31.325224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af78eaf53c154ede9107c635c658d6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8537803,
     "sourceId": 77665,
     "sourceType": "competition"
    },
    {
     "datasetId": 5024070,
     "sourceId": 8435152,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5141018,
     "sourceId": 8594013,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
